{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pyspark.sql.types as stypes\n",
    "import operator\n",
    "import math\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as sfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = spark.read.json('gs://lbanor/dataproc_example/intermediary/2017-11-02',\n",
    "                     schema=_load_users_matrix_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_users_matrix_schema():\n",
    "    \"\"\"Loads schema with data type [user, [(sku, score), (sku, score)]]\n",
    "    :rtype: `pyspark.sql.type.StructType`\n",
    "    :returns: schema speficiation for user -> (sku, score) data.\n",
    "    \"\"\"\n",
    "    return stypes.StructType(fields=[\n",
    "        stypes.StructField(\"user\", stypes.StringType()),\n",
    "         stypes.StructField('interactions', stypes.ArrayType(\n",
    "          stypes.StructType(fields=[stypes.StructField('item', \n",
    "           stypes.StringType()), stypes.StructField('score', \n",
    "            stypes.FloatType())])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stypes.ArrayType?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = stypes.StructType(fields=[stypes.StructField('user', stypes.StringType()),\n",
    "                                   stypes.StructField('interactions', stypes.ArrayType(\n",
    "                                    stypes.StructType(fields=[stypes.StructField('item', stypes.StringType()),\n",
    "                                                              stypes.StructField('score', stypes.FloatType())])))])\n",
    "#schema = stypes.StructType(fields=[stypes.StructField('user', stypes.StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.createDataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.parallelize([['user0', [('sku0', 0.5), ('sku1', 1.5)]]])\n",
    "#data = sc.parallelize([['user0']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.createOrReplaceTempView('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select user, interactions.score from(select user, explode(interactions) interactions from test1)\").createOrReplaceTempView('tt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from tt limit 10\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_intersections(row):\n",
    "    r = []\n",
    "    for i in range(len(row)):\n",
    "        for j in range(i + 1, len(row)):\n",
    "            r.append((row[i][0], row[j][0], row[i][1] * row[j][1]))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_norms(row):\n",
    "    return [(e[0], e[1] ** 2) for e in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_intersections(row):\n",
    "    return [('sku0', 'sku1', 1.), ('sku1', 'sku2', 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.udf.register?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.udf.register(\"correlations\", process_intersections, returnType=stypes.ArrayType(stypes.StructType(fields=[stypes.StructField('sku0', stypes.StringType()), stypes.StructField('sku1', stypes.StringType()), stypes.StructField('cor', stypes.FloatType())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.udf.register(\"SQUARED\", process_norms, returnType=stypes.ArrayType(stypes.StructType(fields=[stypes.StructField('sku0', stypes.StringType()), stypes.StructField('norm', stypes.FloatType())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "a.sku0 sku0,\n",
    "a.sku1 sku1,\n",
    "a.cor / (b.norm * c.norm) similarity\n",
    "FROM(\n",
    "    SELECT\n",
    "      inter.sku0 sku0,\n",
    "      inter.sku1 sku1,\n",
    "      SUM(inter.cor) cor\n",
    "    FROM(\n",
    "      SELECT\n",
    "        EXPLODE(CORRELATIONS(interactions)) inter\n",
    "      FROM test1\n",
    "      WHERE SIZE(interactions) BETWEEN 2 AND 20\n",
    "      )\n",
    "    GROUP BY 1, 2\n",
    "    ) a\n",
    "JOIN (\n",
    "SELECT \n",
    "  sku0,\n",
    "  norm\n",
    "FROM test2\n",
    ") b\n",
    "ON a.sku0 = b.sku0\n",
    "JOIN (\n",
    "SELECT \n",
    "  sku0,\n",
    "  norm\n",
    "FROM test2\n",
    ") c\n",
    "ON a.sku1 = c.sku0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT\n",
    "  norms.sku0 sku0,\n",
    "  SQRT(SUM(norms.norm)) norm\n",
    "FROM(\n",
    "  SELECT\n",
    "    EXPLODE(SQUARED(interactions)) norms\n",
    "  FROM test1\n",
    "  WHERE SIZE(interactions) BETWEEN 2 AND 20\n",
    "  )\n",
    "GROUP BY 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM test2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(query3).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cors = spark.sql(query)\n",
    "cors.createOrReplaceTempView('test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t3 = spark.sql(query2)\n",
    "t3.createOrReplaceTempView('test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfunc.size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_final =\"\"\"\n",
    "SELECT\n",
    "sku0 as item,\n",
    "COLLECT_LIST(STRUCT(sku1 as item, similarity)) similarity_items\n",
    "FROM(\n",
    "SELECT\n",
    "  *\n",
    "FROM(\n",
    "SELECT\n",
    "  sku0,\n",
    "  sku1,\n",
    "  similarity\n",
    "FROM test3\n",
    ") UNION ALL\n",
    "(\n",
    "SELECT\n",
    "  sku1 as sku0,\n",
    "  sku0 as sku1,\n",
    "  similarity\n",
    "FROM test3\n",
    ")\n",
    ")\n",
    "GROUP BY 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = spark.sql(query_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.write.json('gs://lbanor/dataproc_example/df_naive/', compression='gzip', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfunc.struct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_neighbor_schema(self):\n",
    "    \"\"\"Loads neighborhood schema for similarity matrix\n",
    "    :rtype: `pyspark.sql.types.StructField`\n",
    "    :returns: schema of type [\"key\", [(\"key\", \"value\")]]\n",
    "    \"\"\"\n",
    "    return stypes.StructType(fields=[\n",
    "            stypes.StructField(\"item\", stypes.StringType()),\n",
    "             stypes.StructField(\"similarity_items\", stypes.ArrayType(\n",
    "              stypes.StructType(fields=[\n",
    "               stypes.StructField(\"item\", stypes.StringType()),\n",
    "                stypes.StructField(\"similarity\", stypes.FloatType())])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty = sqlContext.createDataFrame(sc.emptyRDD(), schema=load_users_matrix_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty.union(t).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.context import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SQLContext?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.udf.register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.createDataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int('5', 16) * pow(16, 3) + int('9', 16) * pow(16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = sc.parallelize([(0, u'{\"colA\":\"Value1,Value4\"}'), (52, u'{\"colA\":\"Value2\"}')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.map(lambda x: ([json.loads(x[1])['colA']])).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
